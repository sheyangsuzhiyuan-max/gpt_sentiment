{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header_cell",
   "metadata": {},
   "source": [
    "# 01 - æ¢ç´¢æ€§æ•°æ®åˆ†æä¸é¢„å¤„ç† (EDA & Preprocessing)\n",
    "\n",
    "æœ¬ notebook å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š\n",
    "1. åŠ è½½åŸå§‹æ•°æ®\n",
    "2. æ•°æ®æ¢ç´¢ä¸å¯è§†åŒ–\n",
    "3. æ–‡æœ¬æ¸…æ´—ä¸é¢„å¤„ç†\n",
    "4. ä¿å­˜å¤„ç†åçš„æ•°æ®\n",
    "\n",
    "**ä¼˜åŒ–å†…å®¹**ï¼š\n",
    "- ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®æ–‡ä»¶å’Œå·¥å…·å‡½æ•°\n",
    "- æ·»åŠ éšæœºç§å­è®¾ç½®\n",
    "- æ·»åŠ æ•°æ®éªŒè¯\n",
    "- ä¼˜åŒ–æ–‡æœ¬æ¸…æ´—ï¼ˆå¯é€‰æ‹©æ˜¯å¦ç§»é™¤åœç”¨è¯ï¼‰\n",
    "- æ·»åŠ æ—¥å¿—è®°å½•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: ç¯å¢ƒè®¾ç½®ä¸å¯¼å…¥\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "# å¯¼å…¥é¡¹ç›®é…ç½®å’Œå·¥å…·\n",
    "import config\n",
    "import utils\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "utils.set_seed()\n",
    "\n",
    "# è®¾ç½®æ—¥å¿—\n",
    "logger = utils.setup_logger(\n",
    "    'EDA_Preprocess',\n",
    "    log_file=os.path.join(config.LOGS_DIR, 'eda_preprocess.log')\n",
    ")\n",
    "\n",
    "# è®¾ç½®ç”»å›¾é£æ ¼\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# æ˜¾ç¤ºç¯å¢ƒä¿¡æ¯\n",
    "print(\"=\" * 60)\n",
    "print(\"ç¯å¢ƒé…ç½®ä¿¡æ¯\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"è¿è¡Œè®¾å¤‡: {utils.get_device_info()}\")\n",
    "print(f\"éšæœºç§å­: {config.RANDOM_SEED}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "logger.info(\"ç¯å¢ƒè®¾ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: åŠ è½½åŸå§‹æ•°æ®\n",
    "try:\n",
    "    # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡ä»¶æŸ¥æ‰¾å‡½æ•°\n",
    "    data_path = utils.find_data_file(config.RAW_DATA_FILE)\n",
    "    logger.info(f\"æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {data_path}\")\n",
    "    \n",
    "    # è¯»å–æ•°æ®\n",
    "    df = pd.read_csv(data_path)\n",
    "    logger.info(f\"æ•°æ®åŠ è½½æˆåŠŸï¼Œå…± {len(df)} æ¡è®°å½•\")\n",
    "    \n",
    "    print(f\"\\nâœ… æ•°æ®åŠ è½½æˆåŠŸï¼\")\n",
    "    print(f\"ğŸ“Š æ€»æ ·æœ¬æ•°: {len(df):,}\")\n",
    "    print(f\"ğŸ“‹ åˆ—å: {df.columns.tolist()}\")\n",
    "    print(f\"ğŸ’¾ æ•°æ®å¤§å°: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # æ•°æ®åŸºæœ¬ä¿¡æ¯\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"æ•°æ®åŸºæœ¬ä¿¡æ¯\")\n",
    "    print(\"=\" * 60)\n",
    "    print(df.info())\n",
    "    \n",
    "    # å‰5è¡Œé¢„è§ˆ\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"å‰ 5 è¡Œæ•°æ®é¢„è§ˆ\")\n",
    "    print(\"=\" * 60)\n",
    "    display(df.head())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    logger.error(str(e))\n",
    "    print(f\"âŒ é”™è¯¯: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_validation_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: æ•°æ®éªŒè¯ä¸æ¸…æ´—\n",
    "print(\"=\" * 60)\n",
    "print(\"æ•°æ®è´¨é‡æ£€æŸ¥\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# æ£€æŸ¥å¿…éœ€åˆ—\n",
    "required_columns = [config.TEXT_COLUMN, config.LABEL_COLUMN]\n",
    "try:\n",
    "    utils.validate_dataframe(df, required_columns)\n",
    "    logger.info(\"æ•°æ®åˆ—éªŒè¯é€šè¿‡\")\n",
    "    print(\"âœ… å¿…éœ€åˆ—éªŒè¯é€šè¿‡\")\n",
    "except ValueError as e:\n",
    "    logger.error(str(e))\n",
    "    print(f\"âŒ {e}\")\n",
    "    raise\n",
    "\n",
    "# æ£€æŸ¥ç¼ºå¤±å€¼\n",
    "missing_info = df[required_columns].isnull().sum()\n",
    "print(f\"\\nğŸ“Š ç¼ºå¤±å€¼ç»Ÿè®¡:\")\n",
    "print(missing_info)\n",
    "\n",
    "if missing_info.sum() > 0:\n",
    "    print(f\"\\nâš ï¸  å‘ç° {missing_info.sum()} ä¸ªç¼ºå¤±å€¼ï¼Œå°†è¢«åˆ é™¤\")\n",
    "    logger.warning(f\"å‘ç° {missing_info.sum()} ä¸ªç¼ºå¤±å€¼\")\n",
    "    df = df.dropna(subset=required_columns)\n",
    "    print(f\"âœ… æ¸…æ´—åå‰©ä½™ {len(df):,} æ¡è®°å½•\")\n",
    "    logger.info(f\"åˆ é™¤ç¼ºå¤±å€¼åå‰©ä½™ {len(df)} æ¡è®°å½•\")\n",
    "else:\n",
    "    print(\"\\nâœ… æ— ç¼ºå¤±å€¼\")\n",
    "\n",
    "# æ£€æŸ¥é‡å¤å€¼\n",
    "duplicates = df.duplicated(subset=[config.TEXT_COLUMN]).sum()\n",
    "print(f\"\\nğŸ“Š é‡å¤æ ·æœ¬æ•°: {duplicates:,} ({duplicates/len(df)*100:.2f}%)\")\n",
    "if duplicates > 0:\n",
    "    logger.info(f\"å‘ç° {duplicates} ä¸ªé‡å¤æ ·æœ¬\")\n",
    "    print(\"ğŸ’¡ æç¤º: å¯ä»¥é€‰æ‹©æ˜¯å¦åˆ é™¤é‡å¤é¡¹ï¼ˆæœ¬ç¤ºä¾‹ä¿ç•™ï¼‰\")\n",
    "\n",
    "# æ£€æŸ¥æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ\n",
    "df['text_length'] = df[config.TEXT_COLUMN].str.len()\n",
    "print(f\"\\nğŸ“Š æ–‡æœ¬é•¿åº¦ç»Ÿè®¡:\")\n",
    "print(df['text_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_visualization_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: æ¢ç´¢æ€§æ•°æ®åˆ†æ - æ ‡ç­¾åˆ†å¸ƒ\n",
    "print(\"=\" * 60)\n",
    "print(\"æ ‡ç­¾åˆ†å¸ƒåˆ†æ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ç»Ÿè®¡å„ç±»åˆ«æ•°é‡\n",
    "label_counts = df[config.LABEL_COLUMN].value_counts()\n",
    "print(f\"\\n{config.LABEL_COLUMN} åˆ†å¸ƒ:\")\n",
    "for label, count in label_counts.items():\n",
    "    percentage = count / len(df) * 100\n",
    "    print(f\"  {label:10s}: {count:7,} ({percentage:5.2f}%)\")\n",
    "\n",
    "logger.info(f\"æ ‡ç­¾åˆ†å¸ƒ: {label_counts.to_dict()}\")\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# æŸ±çŠ¶å›¾\n",
    "ax1 = axes[0]\n",
    "bars = ax1.bar(label_counts.index, label_counts.values, \n",
    "               color=[config.SENTIMENT_COLORS.get(l.capitalize(), '#999999') \n",
    "                      for l in label_counts.index])\n",
    "ax1.set_title('Sentiment Distribution (Count)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Sentiment', fontsize=12)\n",
    "ax1.set_ylabel('Count', fontsize=12)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# åœ¨æŸ±å­ä¸Šæ˜¾ç¤ºæ•°å€¼\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{int(height):,}',\n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# é¥¼å›¾\n",
    "ax2 = axes[1]\n",
    "colors = [config.SENTIMENT_COLORS.get(l.capitalize(), '#999999') \n",
    "          for l in label_counts.index]\n",
    "wedges, texts, autotexts = ax2.pie(label_counts.values, \n",
    "                                     labels=label_counts.index,\n",
    "                                     autopct='%1.1f%%',\n",
    "                                     colors=colors,\n",
    "                                     startangle=90)\n",
    "ax2.set_title('Sentiment Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# ç¾åŒ–ç™¾åˆ†æ¯”æ–‡å­—\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontsize(11)\n",
    "    autotext.set_fontweight('bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# æ£€æŸ¥ç±»åˆ«ä¸å¹³è¡¡\n",
    "imbalance_ratio = label_counts.max() / label_counts.min()\n",
    "if imbalance_ratio > 3:\n",
    "    print(f\"\\nâš ï¸  æ•°æ®å­˜åœ¨ç±»åˆ«ä¸å¹³è¡¡ (æœ€å¤§ç±»/æœ€å°ç±» = {imbalance_ratio:.2f})\")\n",
    "    print(\"ğŸ’¡ å»ºè®®: è®­ç»ƒæ—¶è€ƒè™‘ä½¿ç”¨ç±»åˆ«æƒé‡æˆ–é‡é‡‡æ ·æŠ€æœ¯\")\n",
    "    logger.warning(f\"ç±»åˆ«ä¸å¹³è¡¡æ¯”ä¾‹: {imbalance_ratio:.2f}\")\n",
    "else:\n",
    "    print(f\"\\nâœ… ç±»åˆ«åˆ†å¸ƒç›¸å¯¹å‡è¡¡ (æ¯”ä¾‹: {imbalance_ratio:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "text_length_analysis_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: æ–‡æœ¬é•¿åº¦åˆ†æ\n",
    "print(\"=\" * 60)\n",
    "print(\"æ–‡æœ¬é•¿åº¦åˆ†æ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# æŒ‰æ ‡ç­¾ç»Ÿè®¡æ–‡æœ¬é•¿åº¦\n",
    "print(\"\\næŒ‰æƒ…æ„Ÿç±»åˆ«ç»Ÿè®¡æ–‡æœ¬é•¿åº¦:\")\n",
    "for label in df[config.LABEL_COLUMN].unique():\n",
    "    subset = df[df[config.LABEL_COLUMN] == label]['text_length']\n",
    "    print(f\"\\n{label.upper()}:\")\n",
    "    print(f\"  å¹³å‡é•¿åº¦: {subset.mean():.1f}\")\n",
    "    print(f\"  ä¸­ä½æ•°: {subset.median():.1f}\")\n",
    "    print(f\"  æ ‡å‡†å·®: {subset.std():.1f}\")\n",
    "\n",
    "# å¯è§†åŒ–æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# æ€»ä½“åˆ†å¸ƒ\n",
    "ax1 = axes[0]\n",
    "ax1.hist(df['text_length'], bins=50, edgecolor='black', alpha=0.7)\n",
    "ax1.axvline(df['text_length'].mean(), color='red', linestyle='--', \n",
    "            label=f'Mean: {df[\"text_length\"].mean():.1f}')\n",
    "ax1.axvline(df['text_length'].median(), color='green', linestyle='--',\n",
    "            label=f'Median: {df[\"text_length\"].median():.1f}')\n",
    "ax1.set_title('Text Length Distribution (Overall)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Text Length (characters)', fontsize=12)\n",
    "ax1.set_ylabel('Frequency', fontsize=12)\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# æŒ‰ç±»åˆ«åˆ†å¸ƒ\n",
    "ax2 = axes[1]\n",
    "for label in df[config.LABEL_COLUMN].unique():\n",
    "    subset = df[df[config.LABEL_COLUMN] == label]['text_length']\n",
    "    color = config.SENTIMENT_COLORS.get(label.capitalize(), '#999999')\n",
    "    ax2.hist(subset, bins=30, alpha=0.5, label=label, color=color, edgecolor='black')\n",
    "\n",
    "ax2.set_title('Text Length Distribution by Sentiment', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Text Length (characters)', fontsize=12)\n",
    "ax2.set_ylabel('Frequency', fontsize=12)\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "text_cleaning_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: æ–‡æœ¬æ¸…æ´—\n",
    "print(\"=\" * 60)\n",
    "print(\"æ–‡æœ¬æ¸…æ´—\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# æ¸…æ´—æ–‡æœ¬\n",
    "print(\"\\nâ³ æ­£åœ¨æ¸…æ´—æ–‡æœ¬...\")\n",
    "df[config.CLEANED_TEXT_COLUMN] = df[config.TEXT_COLUMN].apply(utils.clean_text)\n",
    "logger.info(\"æ–‡æœ¬æ¸…æ´—å®Œæˆ\")\n",
    "\n",
    "# å¯é€‰ï¼šç§»é™¤åœç”¨è¯ï¼ˆé»˜è®¤ä¸ç§»é™¤ï¼Œä¿ç•™æ›´å¤šè¯­ä¹‰ä¿¡æ¯ï¼‰\n",
    "REMOVE_STOPWORDS = False  # è®¾ç½®ä¸º True ä»¥ç§»é™¤åœç”¨è¯\n",
    "\n",
    "if REMOVE_STOPWORDS:\n",
    "    print(\"â³ æ­£åœ¨ç§»é™¤åœç”¨è¯...\")\n",
    "    df[config.CLEANED_TEXT_COLUMN] = df[config.CLEANED_TEXT_COLUMN].apply(\n",
    "        utils.remove_stopwords\n",
    "    )\n",
    "    logger.info(\"åœç”¨è¯ç§»é™¤å®Œæˆ\")\n",
    "    print(\"âœ… åœç”¨è¯å·²ç§»é™¤\")\n",
    "else:\n",
    "    print(\"ğŸ’¡ ä¿ç•™åœç”¨è¯ï¼ˆæ›´é€‚åˆæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼‰\")\n",
    "\n",
    "print(\"\\nâœ… æ–‡æœ¬æ¸…æ´—å®Œæˆï¼\")\n",
    "\n",
    "# å±•ç¤ºæ¸…æ´—å‰åå¯¹æ¯”\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"æ¸…æ´—å‰åå¯¹æ¯”ï¼ˆå‰ 3 ä¸ªæ ·æœ¬ï¼‰\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_df = df[[config.TEXT_COLUMN, config.CLEANED_TEXT_COLUMN]].head(3)\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    print(f\"\\næ ·æœ¬ {idx + 1}:\")\n",
    "    print(f\"åŸæ–‡: {row[config.TEXT_COLUMN][:100]}...\")\n",
    "    print(f\"æ¸…æ´—å: {row[config.CLEANED_TEXT_COLUMN][:100]}...\")\n",
    "\n",
    "# æ£€æŸ¥æ¸…æ´—åæ˜¯å¦æœ‰ç©ºæ–‡æœ¬\n",
    "empty_texts = df[config.CLEANED_TEXT_COLUMN].str.strip().eq('').sum()\n",
    "if empty_texts > 0:\n",
    "    print(f\"\\nâš ï¸  å‘ç° {empty_texts} ä¸ªç©ºæ–‡æœ¬ï¼Œå°†è¢«åˆ é™¤\")\n",
    "    df = df[df[config.CLEANED_TEXT_COLUMN].str.strip() != '']\n",
    "    logger.warning(f\"åˆ é™¤ {empty_texts} ä¸ªç©ºæ–‡æœ¬\")\n",
    "    print(f\"âœ… æ¸…æ´—åå‰©ä½™ {len(df):,} æ¡è®°å½•\")\n",
    "else:\n",
    "    print(\"\\nâœ… æ— ç©ºæ–‡æœ¬\")\n",
    "\n",
    "# ç»Ÿè®¡æ¸…æ´—åçš„æ–‡æœ¬é•¿åº¦\n",
    "df['cleaned_text_length'] = df[config.CLEANED_TEXT_COLUMN].str.len()\n",
    "print(f\"\\nğŸ“Š æ¸…æ´—åæ–‡æœ¬é•¿åº¦ç»Ÿè®¡:\")\n",
    "print(df['cleaned_text_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_data_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: ä¿å­˜å¤„ç†åçš„æ•°æ®\n",
    "print(\"=\" * 60)\n",
    "print(\"ä¿å­˜å¤„ç†åçš„æ•°æ®\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# åˆ é™¤ä¸´æ—¶åˆ—\n",
    "df = df.drop(columns=['text_length', 'cleaned_text_length'], errors='ignore')\n",
    "\n",
    "# ä¿å­˜è·¯å¾„\n",
    "save_path = os.path.join(config.DATA_DIR, config.PROCESSED_DATA_FILE)\n",
    "\n",
    "# ä¿å­˜æ•°æ®\n",
    "config.create_dirs()  # ç¡®ä¿ç›®å½•å­˜åœ¨\n",
    "df.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"\\nâœ… æ•°æ®å·²ä¿å­˜åˆ°: {save_path}\")\n",
    "print(f\"ğŸ“Š ä¿å­˜è®°å½•æ•°: {len(df):,}\")\n",
    "print(f\"ğŸ“‹ ä¿å­˜åˆ—: {df.columns.tolist()}\")\n",
    "print(f\"ğŸ’¾ æ–‡ä»¶å¤§å°: {os.path.getsize(save_path) / 1024**2:.2f} MB\")\n",
    "\n",
    "logger.info(f\"æ•°æ®å·²ä¿å­˜: {save_path}, å…± {len(df)} æ¡è®°å½•\")\n",
    "\n",
    "# æœ€ç»ˆæ•°æ®é¢„è§ˆ\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"æœ€ç»ˆæ•°æ®é¢„è§ˆ\")\n",
    "print(\"=\" * 60)\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… EDA ä¸é¢„å¤„ç†å®Œæˆï¼\")\n",
    "print(\"=\" * 60)\n",
    "print(\"ä¸‹ä¸€æ­¥: è¿è¡Œ 02_Baseline_Model.ipynb è®­ç»ƒåŸºçº¿æ¨¡å‹\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
