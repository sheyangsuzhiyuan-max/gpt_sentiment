{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7c33439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpt_senti/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/opt/anaconda3/envs/gpt_senti/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <0B7EB158-53DC-3403-8A49-22178CAB4612> /opt/anaconda3/envs/gpt_senti/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/opt/anaconda3/envs/gpt_senti/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/gpt_senti/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/gpt_senti/lib/python3.10/lib-dynload/../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/gpt_senti/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前设备: mps\n",
      "标签映射: {'bad': 0, 'neutral': 1, 'good': 2}\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: 准备环境\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"当前设备:\", device)\n",
    "\n",
    "# 和 03 / 04 notebook 保持一致\n",
    "label_map = {'bad': 0, 'neutral': 1, 'good': 2}\n",
    "id2label = {v: k for k, v in label_map.items()}\n",
    "print(\"标签映射:\", label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c74962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据路径: ../data/processed_data.csv\n",
      "总样本数: 219294\n",
      "列名: ['Unnamed: 0', 'tweets', 'labels', 'cleaned_text']\n",
      "\n",
      "前 3 行预览：\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>labels</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chatgpt optimizing language models for dialogue</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>try talking with chatgpt our new ai system whi...</td>\n",
       "      <td>good</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chatgpt optimizing language models for dialogu...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text   labels  label_id\n",
       "0    chatgpt optimizing language models for dialogue  neutral         1\n",
       "1  try talking with chatgpt our new ai system whi...     good         2\n",
       "2  chatgpt optimizing language models for dialogu...  neutral         1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 2: 加载 processed_data.csv\n",
    "\n",
    "filename = 'processed_data.csv'\n",
    "\n",
    "if os.path.exists(os.path.join('..', 'data', filename)):\n",
    "    data_path = os.path.join('..', 'data', filename)\n",
    "elif os.path.exists(os.path.join('data', filename)):\n",
    "    data_path = os.path.join('data', filename)\n",
    "else:\n",
    "    raise FileNotFoundError(\"❌ 找不到 processed_data.csv，请确认它在 data/ 或 ../data/ 之下。\")\n",
    "\n",
    "print(\"数据路径:\", data_path)\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"总样本数:\", len(df))\n",
    "print(\"列名:\", df.columns.tolist())\n",
    "\n",
    "# 和训练时一样的清洗逻辑（防止有空值）\n",
    "df = df.dropna(subset=['cleaned_text', 'labels'])\n",
    "\n",
    "# 如果还没有 label_id，就按照 label_map 再建一列\n",
    "if 'label_id' not in df.columns:\n",
    "    df['label_id'] = df['labels'].map(label_map)\n",
    "\n",
    "print(\"\\n前 3 行预览：\")\n",
    "display(df[['cleaned_text', 'labels', 'label_id']].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd5873d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集: 175428 测试集: 43858\n",
      "✅ DataLoader 构建完成，测试批次数: 1371\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: train_test_split，与 04_BERT_Finetune.ipynb 保持一致\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['cleaned_text'],\n",
    "    df['label_id'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"训练集:\", len(X_train), \"测试集:\", len(X_test))\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = list(texts)\n",
    "        self.labels = list(labels)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = int(self.labels[idx])\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            add_special_tokens=True,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# 从 ./model_save 中加载 tokenizer & model（和 app.py 保持一致）\n",
    "model_path = \"./model_save\"\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_path)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "test_dataset = SentimentDataset(X_test, y_test, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"✅ DataLoader 构建完成，测试批次数:\", len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3bc1b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true shape: (43858,)\n",
      "y_pred shape: (43858,)\n",
      "y_prob shape: (43858, 3)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: 推理，收集预测结果\n",
    "import torch.nn.functional as F\n",
    "\n",
    "all_true = []\n",
    "all_pred = []\n",
    "all_probs = []\n",
    "all_texts = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        probs = F.softmax(logits, dim=-1)  # [batch_size, 3]\n",
    "        preds = torch.argmax(probs, dim=-1)\n",
    "        \n",
    "        all_true.extend(labels.cpu().numpy())\n",
    "        all_pred.extend(preds.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "        \n",
    "        # 记录原始文本，方便误差分析\n",
    "        # 注意：这里用的是 X_test 的顺序，DataLoader 没 shuffle\n",
    "        batch_texts = X_test.iloc[batch_idx*test_loader.batch_size : (batch_idx+1)*test_loader.batch_size]\n",
    "        all_texts.extend(batch_texts.tolist())\n",
    "\n",
    "y_true = np.array(all_true)\n",
    "y_pred = np.array(all_pred)\n",
    "y_prob = np.array(all_probs)  # shape: [N, 3]\n",
    "\n",
    "print(\"y_true shape:\", y_true.shape)\n",
    "print(\"y_pred shape:\", y_pred.shape)\n",
    "print(\"y_prob shape:\", y_prob.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2529b56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_df 预览：\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_id</th>\n",
       "      <th>pred_id</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>max_prob</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i asked chatgpt to define productivity and to ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>0.978996</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the ps5 is an elizabethan marvel</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.988305</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just tried chatgpt to help write some blog pos...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.897813</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im onboard with the thought that is going to o...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.990850</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heres a question for the garbageingarbageout f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>0.979215</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  true_id  pred_id  \\\n",
       "0  i asked chatgpt to define productivity and to ...        2        2   \n",
       "1                   the ps5 is an elizabethan marvel        1        1   \n",
       "2  just tried chatgpt to help write some blog pos...        1        1   \n",
       "3  im onboard with the thought that is going to o...        1        1   \n",
       "4  heres a question for the garbageingarbageout f...        0        0   \n",
       "\n",
       "  true_label pred_label  max_prob  text_len  \n",
       "0       good       good  0.978996        32  \n",
       "1    neutral    neutral  0.988305         6  \n",
       "2    neutral    neutral  0.897813        31  \n",
       "3    neutral    neutral  0.990850        18  \n",
       "4        bad        bad  0.979215        25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 5: 构建 eval_df 方便后续 error analysis\n",
    "\n",
    "eval_df = pd.DataFrame({\n",
    "    'text': all_texts,\n",
    "    'true_id': y_true,\n",
    "    'pred_id': y_pred\n",
    "})\n",
    "\n",
    "eval_df['true_label'] = eval_df['true_id'].map(id2label)\n",
    "eval_df['pred_label'] = eval_df['pred_id'].map(id2label)\n",
    "\n",
    "# 记录每个样本的最大置信度\n",
    "eval_df['max_prob'] = y_prob.max(axis=1)\n",
    "\n",
    "# 简单按空格计算文本长度（后面按长度分桶）\n",
    "eval_df['text_len'] = eval_df['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "print(\"eval_df 预览：\")\n",
    "display(eval_df.head())\n",
    "\n",
    "# 以后误差分析都基于 eval_df 做（非常方便）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff62e5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_senti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
