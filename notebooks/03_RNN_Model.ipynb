{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e5f8688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å½“å‰è¿è¡Œè®¾å¤‡: mps\n",
      "âœ… æ•°æ®å‡†å¤‡å°±ç»ªï¼Œå…± 219286 æ¡\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>chatgpt optimizing language models for dialogue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Try talking with ChatGPT, our new AI system wh...</td>\n",
       "      <td>good</td>\n",
       "      <td>try talking with chatgpt our new ai system whi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             tweets   labels  \\\n",
       "0           0  ChatGPT: Optimizing Language Models for Dialog...  neutral   \n",
       "1           1  Try talking with ChatGPT, our new AI system wh...     good   \n",
       "\n",
       "                                        cleaned_text  label_id  \n",
       "0    chatgpt optimizing language models for dialogue         1  \n",
       "1  try talking with chatgpt our new ai system whi...         2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 1: å¯¼å…¥åº“ä¸é…ç½® MPS åŠ é€Ÿ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# 1. è®¾ç½®è®¾å¤‡ (å…³é”®ï¼šä½¿ç”¨ Mac M4 çš„ MPS åŠ é€Ÿ)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"ğŸš€ å½“å‰è¿è¡Œè®¾å¤‡: {device}\")\n",
    "\n",
    "# 2. è¯»å–æ•°æ®\n",
    "filename = 'processed_data.csv'\n",
    "# è‡ªåŠ¨å¯»æ‰¾è·¯å¾„\n",
    "if os.path.exists(os.path.join('..', 'data', filename)):\n",
    "    df = pd.read_csv(os.path.join('..', 'data', filename))\n",
    "elif os.path.exists(os.path.join('data', filename)):\n",
    "    df = pd.read_csv(os.path.join('data', filename))\n",
    "else:\n",
    "    raise FileNotFoundError(\"æ‰¾ä¸åˆ° processed_data.csv\")\n",
    "\n",
    "# è¿‡æ»¤æ‰ç©ºå€¼\n",
    "df = df.dropna(subset=['cleaned_text', 'labels'])\n",
    "\n",
    "# 3. æ ‡ç­¾ç¼–ç  (æŠŠ good/bad/neutral å˜æˆ 0, 1, 2)\n",
    "label_map = {'bad': 0, 'neutral': 1, 'good': 2}\n",
    "df['label_id'] = df['labels'].map(label_map)\n",
    "\n",
    "print(f\"âœ… æ•°æ®å‡†å¤‡å°±ç»ªï¼Œå…± {len(df)} æ¡\")\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37882c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š è¯è¡¨æ„å»ºå®Œæˆï¼ŒåŒ…å« 27506 ä¸ªå•è¯\n",
      "âœ… PyTorch æ•°æ®ç®¡é“æ­å»ºå®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: æ„å»ºè¯è¡¨ä¸ Dataset ç±»\n",
    "# è¿™æ˜¯ä¸€ä¸ªæ‰‹åŠ¨å®ç°çš„ç®€å• Tokenizerï¼Œæ¯”è°ƒç”¨ BERT åº“æ›´ç›´è§‚ï¼Œé€‚åˆå±•ç¤ºåŸç†\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vocab=None, max_len=50):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        # å¦‚æœæ²¡ä¼ è¯è¡¨ï¼Œå°±æ ¹æ®å½“å‰æ•°æ®å»ºç«‹ä¸€ä¸ª\n",
    "        if vocab is None:\n",
    "            all_words = \" \".join(texts).split()\n",
    "            word_counts = Counter(all_words)\n",
    "            # åªä¿ç•™å‡ºç°è¶…è¿‡ 2 æ¬¡çš„è¯ï¼Œå‡å°‘å™ªéŸ³\n",
    "            vocab = {word: i+2 for i, (word, count) in enumerate(word_counts.items()) if count > 2}\n",
    "            vocab['<PAD>'] = 0 # å¡«å……ä½\n",
    "            vocab['<UNK>'] = 1 # æœªçŸ¥è¯\n",
    "            print(f\"ğŸ“š è¯è¡¨æ„å»ºå®Œæˆï¼ŒåŒ…å« {len(vocab)} ä¸ªå•è¯\")\n",
    "        \n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        \n",
    "        # æ–‡æœ¬è½¬æ•°å­—åºåˆ—\n",
    "        tokens = [self.vocab.get(word, 1) for word in text.split()]\n",
    "        \n",
    "        # æˆªæ–­æˆ–å¡«å…… (Padding) ä¿è¯é•¿åº¦ä¸€è‡´\n",
    "        if len(tokens) < self.max_len:\n",
    "            tokens = tokens + [0] * (self.max_len - len(tokens))\n",
    "        else:\n",
    "            tokens = tokens[:self.max_len]\n",
    "            \n",
    "        return torch.tensor(tokens, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# åˆ’åˆ†æ•°æ®é›†\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['label_id'], test_size=0.2, random_state=42)\n",
    "\n",
    "# åˆ›å»º Dataset å®ä¾‹\n",
    "train_dataset = TextDataset(X_train, y_train)\n",
    "test_dataset = TextDataset(X_test, y_test, vocab=train_dataset.vocab) # æµ‹è¯•é›†å¿…é¡»ç”¨è®­ç»ƒé›†çš„è¯è¡¨ï¼\n",
    "\n",
    "# åˆ›å»º DataLoader (æ‰¹é‡æ¬è¿å·¥)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"âœ… PyTorch æ•°æ®ç®¡é“æ­å»ºå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e40c494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ å¼€å§‹è®­ç»ƒ RNN æ¨¡å‹ (ä½¿ç”¨ MPS åŠ é€Ÿ)...\n",
      "Epoch [1/5], Loss: 0.6369, Train Acc: 73.94%\n",
      "Epoch [2/5], Loss: 0.3625, Train Acc: 87.41%\n",
      "Epoch [3/5], Loss: 0.2833, Train Acc: 90.55%\n",
      "Epoch [4/5], Loss: 0.2422, Train Acc: 92.03%\n",
      "Epoch [5/5], Loss: 0.2109, Train Acc: 93.12%\n",
      "ğŸ‰ è®­ç»ƒå®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: å®šä¹‰ LSTM æ¨¡å‹ä¸è®­ç»ƒå¾ªç¯\n",
    "\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=100, hidden_dim=128, num_classes=3):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        # 1. è¯åµŒå…¥å±‚ï¼šæŠŠæ•°å­—IDå˜æˆå‘é‡\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        # 2. LSTM å±‚ï¼šæ•æ‰åºåˆ—ç‰¹å¾\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        # 3. å…¨è¿æ¥å±‚ï¼šè¾“å‡ºåˆ†ç±»ç»“æœ\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        # LSTM è¿”å›: output, (hidden_state, cell_state)\n",
    "        # æˆ‘ä»¬åªéœ€è¦æœ€åä¸€æ­¥çš„ hidden_state\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        out = self.fc(h_n[-1]) # å–æœ€åä¸€å±‚çš„çŠ¶æ€\n",
    "        return out\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "vocab_size = len(train_dataset.vocab)\n",
    "model = RNNClassifier(vocab_size).to(device) # æŠŠæ¨¡å‹æ¬åˆ° GPU ä¸Š\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# === è®­ç»ƒå¾ªç¯ ===\n",
    "print(\"ğŸ”¥ å¼€å§‹è®­ç»ƒ RNN æ¨¡å‹ (ä½¿ç”¨ MPS åŠ é€Ÿ)...\")\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        # æ¬è¿æ•°æ®åˆ° GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # å‰å‘ä¼ æ’­\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # åå‘ä¼ æ’­\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}, Train Acc: {100 * correct / total:.2f}%\")\n",
    "\n",
    "print(\"ğŸ‰ è®­ç»ƒå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4e397fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ† RNN æ¨¡å‹è¯„ä¼°æŠ¥å‘Š:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.95      0.94      0.95     21504\n",
      "     neutral       0.82      0.82      0.82     11075\n",
      "        good       0.90      0.90      0.90     11279\n",
      "\n",
      "    accuracy                           0.90     43858\n",
      "   macro avg       0.89      0.89      0.89     43858\n",
      "weighted avg       0.90      0.90      0.90     43858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: è¯„ä¼°æ¨¡å‹\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(\"\\nğŸ† RNN æ¨¡å‹è¯„ä¼°æŠ¥å‘Š:\")\n",
    "# è¿˜åŸæ ‡ç­¾å\n",
    "target_names = ['bad', 'neutral', 'good'] # å¯¹åº” 0, 1, 2\n",
    "print(classification_report(all_labels, all_preds, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_senti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
